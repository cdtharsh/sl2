import tensorflow as tf

from tensorflow.keras import layers, models, datasets



# Step 1: Load and Preprocess Data

(train_images, train_labels), (test_images, test_labels) = datasets.mnist.load_data()

train_images, test_images = train_images / 255.0, test_images / 255.0



# Step 2: Define the Neural Network Architecture

model = models.Sequential([

    layers.Flatten(input_shape=(28, 28)),

    layers.Dense(128, activation='relu'),

    layers.Dropout(0.2),

    layers.Dense(10)

])



# Step 3: Compile the Model

model.compile(optimizer='adam',

              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),

              metrics=['accuracy'])



# Step 4: Train the Model

model.fit(train_images, train_labels, epochs=5)



# Step 5: Evaluate the Model

test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)

print(f'Test accuracy: {test_acc}')


!pip install torchvision
import torch

import torchvision

import torch.nn as nn

import torch.optim as optim

import torchvision.transforms as transforms



# Step 1: Load and Preprocess Data

transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])

train_set = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)

train_loader = torch.utils.data.DataLoader(train_set, batch_size=64, shuffle=True)



# Step 2: Define the Neural Network Architecture

class Net(nn.Module):

    def __init__(self):

        super(Net, self).__init__()

        self.conv1 = nn.Conv2d(1, 32, kernel_size=3)

        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)

        self.fc1 = nn.Linear(1600, 128)

        self.fc2 = nn.Linear(128, 10)



    def forward(self, x):

        x = torch.relu(self.conv1(x))

        x = torch.max_pool2d(x, kernel_size=2, stride=2)

        x = torch.relu(self.conv2(x))

        x = torch.max_pool2d(x, kernel_size=2, stride=2)

        x = x.view(-1, 1600)

        x = torch.relu(self.fc1(x))

        x = self.fc2(x)

        return x



model = Net()



# Step 3: Define Loss Function and Optimizer

criterion = nn.CrossEntropyLoss()

optimizer = optim.SGD(model.parameters(), lr=0.01)



# Step 4: Train the Model

for epoch in range(5):

    running_loss = 0.0

    for i, data in enumerate(train_loader, 0):

        inputs, labels = data

        optimizer.zero_grad()

        outputs = model(inputs)

        loss = criterion(outputs, labels)

        loss.backward()

        optimizer.step()

        running_loss += loss.item()

        if i % 100 == 99:

            print(f'Epoch: {epoch + 1}, Batch: {i + 1}, Loss: {running_loss / 100}')

            running_loss = 0.0



print('Finished Training')
